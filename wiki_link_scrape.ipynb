{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39448528-8235-4bfa-9507-4fcbe4f6a5dc",
   "metadata": {},
   "source": [
    "This is a wikipedia link scraper that I made to find \"Degrees of Separation to Kevin Bacon (on wikipedia)\". However, I decided to just stick to one-degree of separation because of the exponential growth of links to scrape at multiple levels. If you decide to wrap this in a loop to explore more degrees of separation, be prepared for a long wait for a full scrape! Saving this here for future wiki-scraping needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401ff344-644c-4e9a-b40f-54f7e9132d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed packages and definitions\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# --- functions ---\n",
    "\n",
    "def is_valid(url):\n",
    "    \"\"\"finding the valid link\"\"\"\n",
    "\n",
    "    if url:\n",
    "        if url.startswith('/wiki/'): # just get internal /wiki/ links\n",
    "            if not re.compile(r'/\\w+:').search(url):\n",
    "                return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa1cc7ec-ebca-4df6-a05d-ef397762a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting wiki page: https://en.wikipedia.org/wiki/John_Belushi\n",
      "title: John Belushi\n",
      "\n",
      "Total Links: 299\n"
     ]
    }
   ],
   "source": [
    "# Counts the number of Wikipedia links in a given start page\n",
    "\n",
    "random_url = 'https://en.wikipedia.org/wiki/John_Belushi'\n",
    "\n",
    "r = requests.get(random_url)\n",
    "#print('url:', r.url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "title = soup.find('h1', {'class': 'firstHeading'})\n",
    "\n",
    "print('starting wiki page:', r.url)\n",
    "print('title:', title.text)\n",
    "print()\n",
    "\n",
    "valid_urls = []\n",
    "valid_url_whl = []\n",
    "\n",
    "for link in soup.find_all('a'): # find_all('a', {'href': True}):\n",
    "    url = link.get('href', '')\n",
    "    if url not in valid_urls and is_valid(url):\n",
    "        url_whl = 'https://en.wikipedia.org' + link.get('href', '') #whole URL\n",
    "        valid_urls.append(url)\n",
    "        valid_url_whl.append(url_whl)\n",
    "\n",
    "#print(valid_urls)\n",
    "\n",
    "#for url in valid_urls:        \n",
    "#    print(url)\n",
    "\n",
    "print(\"Total Links:\", len(valid_url_whl))\n",
    "#print()\n",
    "#print(valid_url_whl[3])\n",
    "#print('\\n'.join(valid_urls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd064049-ad70-4a12-bc68-c9b1548b3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting wiki page: https://en.wikipedia.org/wiki/John_Belushi\n",
      "title: John Belushi\n",
      "Kevin Bacon not found in initial Wikipedia article.\n",
      "Bacon Found! 1 degree of Separation! i = 11 -> url: https://en.wikipedia.org/wiki/Animal_House\n",
      "Bacon Found! 1 degree of Separation! i = 38 -> url: https://en.wikipedia.org/wiki/National_Lampoon%27s_Animal_House\n",
      "Bacon Found! 1 degree of Separation! i = 45 -> url: https://en.wikipedia.org/wiki/Paul_Shaffer\n",
      "Bacon Found! 1 degree of Separation! i = 100 -> url: https://en.wikipedia.org/wiki/Jack_Nicholson\n",
      "Bacon Found! 1 degree of Separation! i = 101 -> url: https://en.wikipedia.org/wiki/John_Landis\n",
      "Bacon Found! 1 degree of Separation! i = 106 -> url: https://en.wikipedia.org/wiki/Hollywood_(film_industry)\n",
      "Bacon Found! 1 degree of Separation! i = 122 -> url: https://en.wikipedia.org/wiki/Blair_Brown\n",
      "Bacon Found! 1 degree of Separation! i = 182 -> url: https://en.wikipedia.org/wiki/List_of_actors_with_Hollywood_Walk_of_Fame_motion_picture_stars\n"
     ]
    }
   ],
   "source": [
    "#Finds tne links from a given start page that mention Kevin Bacon. This could be wrapped in another loop to find 'degrees of separation', \n",
    "#but it takes a long time to scrape that exponentially growing number of links!\n",
    "\n",
    "random_url = 'https://en.wikipedia.org/wiki/John_Belushi' #initialize\n",
    "r = requests.get(random_url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "title = soup.find('h1', {'class': 'firstHeading'})\n",
    "print('starting wiki page:', r.url)\n",
    "print('title:', title.text)\n",
    "\n",
    "#bacon_found = None\n",
    "\n",
    "if 'Kevin Bacon' in str(soup):\n",
    "    print (0, ' degrees of separation from Kevin Bacon')\n",
    "else: \n",
    "    print ('Kevin Bacon not found in initial Wikipedia article.')\n",
    "\n",
    "valid_urls = []\n",
    "valid_url_whl = []\n",
    "\n",
    "for link in soup.find_all('a'): # find_all('a', {'href': True}):\n",
    "    url = link.get('href', '')\n",
    "    if url not in valid_urls and is_valid(url):\n",
    "        url_whl = 'https://en.wikipedia.org' + link.get('href', '') #whole URL\n",
    "        valid_urls.append(url)\n",
    "        valid_url_whl.append(url_whl)\n",
    "    \n",
    "for i in range(0,len(valid_url_whl)):\n",
    "    random_url = valid_url_whl[i]\n",
    "    r = requests.get(random_url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        \n",
    "    if 'Kevin Bacon' in str(soup):\n",
    "        #bacon_found == True\n",
    "        print ('Bacon Found! 1 degree of Separation! i =',i,'->','url:', r.url)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b614c8-ae48-41c6-a493-4907407acb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
